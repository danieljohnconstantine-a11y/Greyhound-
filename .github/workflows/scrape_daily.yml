name: Greyhounds â€” Daily scrape

on:
  workflow_dispatch:
  schedule:
    - cron: "05 07 * * *"  # 07:05 UTC ~ evening AEST

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ensure folders
        run: |
          mkdir -p reports/latest
          mkdir -p forms

      # If you already have a job that fetches today's PDFs into forms/, keep it.
      # Otherwise, temporarily rely on existing PDFs in /forms.

      - name: Build daily reports from PDFs
        run: |
          python -m src.run_daily

      - name: Show outputs
        run: |
          echo "=== probabilities.csv ==="
          sed -n '1,40p' reports/latest/probabilities.csv || true
          echo "=== summary.md ==="
          sed -n '1,120p' reports/latest/summary.md || true

      - name: Commit results to repo
        run: |
          git config --local user.email "actions@users.noreply.github.com"
          git config --local user.name "actions-user"
          git add reports/latest
          git commit -m "daily: update betting reports" || echo "nothing to commit"
          git push
