name: Greyhounds — Daily scrape

on:
  workflow_dispatch: {}
  schedule:
    # 09:05 AEST daily ≈ 23:05 UTC; adjust if you want
    - cron: "5 23 * * *"

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    env:
      PYTHONDONTWRITEBYTECODE: "1"
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ensure folders
        run: |
          mkdir -p forms
          mkdir -p data/rns
          mkdir -p reports/latest

      - name: Fetch R&S PDFs (auto-discover + pattern fallback)
        run: |
          python fetch_forms.py --out forms --min-pdfs 1
          ls -lah forms || true

      - name: Build reports from PDFs
        run: |
          python src/run_daily.py
          ls -lah reports/latest || true
          ls -lah data/rns || true

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: greyhounds-output
          path: |
            forms/**
            data/rns/**
            reports/latest/**
          if-no-files-found: warn

      - name: Commit results
        run: |
          git config --local user.email "actions-user@users.noreply.github.com"
          git config --local user.name "actions-user"
          git add -A
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Daily scrape: forms + parsed + reports"
            git push
          fi
