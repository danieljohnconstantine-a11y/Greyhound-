name: Greyhounds — Daily scrape

on:
  workflow_dispatch: {}
  schedule:
    # every day at 05:02 AEST (19:02 UTC previous day) — tweak if you like
    - cron: "2 19 * * *"

permissions:
  contents: write    # allow committing results
  actions: read

concurrency:
  group: daily-scrape
  cancel-in-progress: false

env:
  PYTHONUNBUFFERED: "1"
  TZ: Australia/Sydney
  # polite fixed UA so we don't get 403s as easily
  DEFAULT_UA: "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125 Safari/537.36"

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ensure output folders
        run: |
          mkdir -p data/rns
          mkdir -p data/thedogs
          mkdir -p data/combined
          mkdir -p reports/latest

      # ---------- PRIMARY SOURCE: Racing & Sports ----------
      - name: Racing & Sports — scrape
        id: rns
        env:
          USER_AGENT: ${{ env.DEFAULT_UA }}
        run: |
          set -euxo pipefail
          python src/rns_daily.py --out-dir data/rns || echo "RNS scrape failed (continuing)"

      # ---------- FALLBACK SOURCE: TheDogs ----------
      - name: TheDogs — scrape (fallback)
        id: thedogs
        env:
          USER_AGENT: ${{ env.DEFAULT_UA }}
        run: |
          set -euxo pipefail
          python src/thedogs_daily.py --out-dir data/thedogs || echo "TheDogs scrape failed (continuing)"

      # ---------- MERGE ----------
      - name: Merge to one CSV
        run: |
          set -euxo pipefail
          python src/merge_daily.py --rns data/rns --dogs data/thedogs --out data/combined

      # ---------- QUICK PREVIEWS (optional; doesn’t fail build) ----------
      - name: Show previews
        continue-on-error: true
        run: |
          echo "RNS files:"; ls -la data/rns || true
          echo "TheDogs files:"; ls -la data/thedogs || true
          echo "Combined:"; ls -la data/combined || true
          echo "Reports/latest:"; ls -la reports/latest || true

      # ---------- ARTIFACT ----------
      - name: Upload artifact (zip of data/* and reports/latest)
        uses: actions/upload-artifact@v4
        with:
          name: greyhounds-data
          path: |
            data
            reports/latest

      # ---------- COMMIT BACK ----------
      - name: Commit results to repo (if changed)
        run: |
          set -euxo pipefail
          git config --local user.name "actions-user"
          git config --local user.email "actions@users.noreply.github.com"
          git add -A

          # commit only if there are changes
          if ! git diff --cached --quiet; then
            ts=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
            git commit -m "Daily scrape: update data and reports ($ts)"
            git push
          else
            echo "No changes to commit."
          fi
