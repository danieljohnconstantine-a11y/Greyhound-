name: Run Greyhound Scraper

on:
  schedule:
    - cron: "5 22 * * *"   # ~08:05 AEST
    - cron: "5 21 * * *"   # ~08:05 AEDT
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      TZ: Australia/Sydney
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run scraper
        run: |
          # adjust to your actual scraper command/file
          python scraper.py
      - name: Commit scraped outputs (if any)
        run: |
          git config user.email "actions@github.com"
          git config user.name "github-actions[bot]"
          git add -A forms data || true
          git commit -m "chore(scraper): update data" || echo "nothing to commit"
          git push
